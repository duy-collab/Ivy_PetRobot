# Ivy_PetRobot

Ivy_PetRobot is an interactive AI-powered pet robot designed to engage with users through voice, facial recognition, and dynamic behaviors. It brings personality to robotics with a focus on emotional expression and smart interaction.

## Features

- ğŸ¤ Voice recognition using Whisper
- ğŸ—£ï¸ Speech synthesis with natural voice
- ğŸ§  AI-powered conversation using OpenAI API
- ğŸ“· Image recognition and scene description
- ğŸ˜º Facial emotion display via LCD and LED
- ğŸ› Motor control for mobility and animation
- ğŸ•¹ï¸ ESP32 & Raspberry Pi integration
- ğŸ“¡ MQTT cloud communication with HiveMQ
- ğŸ“ I2C communication for command synchronization

## Technologies Used

- Raspberry Pi OS Bullseye
- ESP32 microcontroller
- INMP441 microphone (I2S)
- MAX98357A speaker amp (I2S)
- ILI9341 / ST7796 LCD with GT911 touch
- OpenAI Whisper and GPT APIs
- HiveMQ MQTT for IoT data streaming
- Python, C++ (Arduino), Bash

## Repository Structure

/Ivy_PetRobot
â”œâ”€â”€ raspberry_pi/ # Main AI logic, image processing, audio I/O

â”œâ”€â”€ esp32/ # Display, motors, expression handling

â”œâ”€â”€ arduino_nano/ # Optional: audio capture and I2C transmission

â”œâ”€â”€ assets/ # Face expression images, sound files

â”œâ”€â”€ docs/ # Reports and design documentation

â””â”€â”€ README.md

## Credits

Final year thesis project by Luong Ho Khanh Duy, Student ID 2113013 and Tran Kim Khanh, Student ID 2113717 â€” Department of Electrical Engineering, Ho Chi Minh City University of Technology (HCMUT).
